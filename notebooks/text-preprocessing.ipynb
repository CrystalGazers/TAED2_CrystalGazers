{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41da21b7",
   "metadata": {},
   "source": [
    "# Crystal Gazers Text Pre-processing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fa956",
   "metadata": {},
   "source": [
    "This notebook is meant to be used as a preliminary visual test of how the text used as the input to the model will be pre-processed. This notebook is is not made to be executed from top to bottom in one execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dcfdd3",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fee8eb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.337978Z",
     "iopub.status.busy": "2022-03-06T18:31:46.336095Z",
     "iopub.status.idle": "2022-03-06T18:31:46.349437Z",
     "shell.execute_reply": "2022-03-06T18:31:46.348582Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.675412Z"
    },
    "papermill": {
     "duration": 0.0334,
     "end_time": "2022-03-06T18:31:46.349609",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.316209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import subprocess\n",
    "import array\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfc16e",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c79df99",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.382350Z",
     "iopub.status.busy": "2022-03-06T18:31:46.381342Z",
     "iopub.status.idle": "2022-03-06T18:31:46.385652Z",
     "shell.execute_reply": "2022-03-06T18:31:46.386214Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.709449Z"
    },
    "papermill": {
     "duration": 0.022311,
     "end_time": "2022-03-06T18:31:46.386387",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.364076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_VERSION = 'ca-100'\n",
    "DATASET_ROOT = f'../input/viquipdia/{DATASET_VERSION}'\n",
    "WORKING_ROOT = f'data/{DATASET_VERSION}'\n",
    "DATASET_PREFIX = 'ca.wiki'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a795370e",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0667a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.418255Z",
     "iopub.status.busy": "2022-03-06T18:31:46.417177Z",
     "iopub.status.idle": "2022-03-06T18:31:46.421599Z",
     "shell.execute_reply": "2022-03-06T18:31:46.422181Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.714939Z"
    },
    "papermill": {
     "duration": 0.02215,
     "end_time": "2022-03-06T18:31:46.422365",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.400215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = SimpleNamespace(\n",
    "    window_size = 7,\n",
    "    cutoff = 3,\n",
    "    maxtokens = 100000,\n",
    "    dataset = f'{DATASET_ROOT}/{DATASET_PREFIX}',\n",
    "    working = f'{WORKING_ROOT}/{DATASET_PREFIX}',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e2366",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a46585",
   "metadata": {},
   "source": [
    "The Vocabulary class defines the vocabulary that the NLP model will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a476feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.454169Z",
     "iopub.status.busy": "2022-03-06T18:31:46.453459Z",
     "iopub.status.idle": "2022-03-06T18:31:46.465004Z",
     "shell.execute_reply": "2022-03-06T18:31:46.465577Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.732967Z"
    },
    "papermill": {
     "duration": 0.029178,
     "end_time": "2022-03-06T18:31:46.465792",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.436614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, pad_token='<pad>', unk_token='<unk>', eos_token='<eos>'):\n",
    "        self.token2idx = {}\n",
    "        self.idx2token = []\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.eos_token = eos_token\n",
    "        if pad_token is not None:\n",
    "            self.pad_index = self.add_token(pad_token)\n",
    "        if unk_token is not None:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "        if eos_token is not None:\n",
    "            self.eos_index = self.add_token(eos_token)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token2idx:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = len(self.idx2token) - 1\n",
    "        return self.token2idx[token]\n",
    "\n",
    "    def get_index(self, token):\n",
    "        if isinstance(token, str):\n",
    "            return self.token2idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return [self.token2idx.get(t, self.unk_index) for t in token]\n",
    "\n",
    "    def get_token(self, index):\n",
    "        return self.idx2token[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.__dict__, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.__dict__.update(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fc519",
   "metadata": {},
   "source": [
    "The following class manages punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd165d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.497226Z",
     "iopub.status.busy": "2022-03-06T18:31:46.496430Z",
     "iopub.status.idle": "2022-03-06T18:31:46.505088Z",
     "shell.execute_reply": "2022-03-06T18:31:46.504363Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.752567Z"
    },
    "papermill": {
     "duration": 0.025325,
     "end_time": "2022-03-06T18:31:46.505236",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.479911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Punctuation:\n",
    "    html = re.compile(r'&apos;|&quot;')\n",
    "    punctuation = re.compile(r'[^\\w\\s·]|_')\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    ela_geminada = re.compile(r'l · l')\n",
    "\n",
    "    def strip(self, s):\n",
    "        '''\n",
    "        Remove all punctuation characters.\n",
    "        '''\n",
    "        s = self.html.sub(' ', s)\n",
    "        s = self.punctuation.sub(' ', s)\n",
    "        s = self.spaces.sub(' ', s).strip()\n",
    "        s = self.ela_geminada.sub('l·l', s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c12222c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.536951Z",
     "iopub.status.busy": "2022-03-06T18:31:46.536237Z",
     "iopub.status.idle": "2022-03-06T18:31:46.542078Z",
     "shell.execute_reply": "2022-03-06T18:31:46.541554Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.767997Z"
    },
    "papermill": {
     "duration": 0.022825,
     "end_time": "2022-03-06T18:31:46.542223",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.519398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(input_path, output_path):\n",
    "    punc = Punctuation()\n",
    "    with open(input_path, 'r', encoding='utf-8') as inpf, open(output_path, 'w', encoding='utf-8') as outf:\n",
    "        for line in inpf:\n",
    "            line = punc.strip(line)\n",
    "            print(line, file=outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f03deeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.577577Z",
     "iopub.status.busy": "2022-03-06T18:31:46.576855Z",
     "iopub.status.idle": "2022-03-06T18:31:46.579709Z",
     "shell.execute_reply": "2022-03-06T18:31:46.579154Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.791405Z"
    },
    "papermill": {
     "duration": 0.023476,
     "end_time": "2022-03-06T18:31:46.579859",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.556383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_counter(file_path):\n",
    "    counter = Counter()\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                tokens = line.split()\n",
    "                counter.update(tokens)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f5d6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.615350Z",
     "iopub.status.busy": "2022-03-06T18:31:46.614607Z",
     "iopub.status.idle": "2022-03-06T18:31:46.617908Z",
     "shell.execute_reply": "2022-03-06T18:31:46.617244Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.808219Z"
    },
    "papermill": {
     "duration": 0.024169,
     "end_time": "2022-03-06T18:31:46.618075",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.593906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_vocabulary(token_counter, cutoff=3, maxtokens=None, verbose=1, eos_token=None):\n",
    "    vocab = Vocabulary(eos_token=eos_token)\n",
    "    total_count = sum(token_counter.values())\n",
    "    in_vocab_count = 0\n",
    "\n",
    "    for token, count in token_counter.most_common(maxtokens):\n",
    "        if count >= cutoff:\n",
    "            vocab.add_token(token)\n",
    "            in_vocab_count += count\n",
    "\n",
    "    if verbose:\n",
    "        OOV_count = total_count - in_vocab_count\n",
    "        print('OOV ratio: %.2f%%.' % (100*OOV_count / total_count))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc087268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.653870Z",
     "iopub.status.busy": "2022-03-06T18:31:46.653201Z",
     "iopub.status.idle": "2022-03-06T18:31:46.656109Z",
     "shell.execute_reply": "2022-03-06T18:31:46.655501Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.828824Z"
    },
    "papermill": {
     "duration": 0.02374,
     "end_time": "2022-03-06T18:31:46.656255",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.632515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_index(file_path, vocab, eos_token=None):\n",
    "    index_list = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                if eos_token is not None:\n",
    "                    line += ' ' + eos_token\n",
    "                tokens = line.strip().split()\n",
    "                index_list.append([vocab.get_index(token) for token in tokens])\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13285e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.687682Z",
     "iopub.status.busy": "2022-03-06T18:31:46.687016Z",
     "iopub.status.idle": "2022-03-06T18:31:46.693178Z",
     "shell.execute_reply": "2022-03-06T18:31:46.692532Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.848420Z"
    },
    "papermill": {
     "duration": 0.023239,
     "end_time": "2022-03-06T18:31:46.693481",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.670242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_number_of_samples(idx_list, window_size):\n",
    "    nsamples = 0\n",
    "    for line in idx_list:\n",
    "        if len(line) <= window_size // 2:\n",
    "            continue\n",
    "        nsamples += len(line)\n",
    "    return nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19bd046b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.732038Z",
     "iopub.status.busy": "2022-03-06T18:31:46.730787Z",
     "iopub.status.idle": "2022-03-06T18:31:46.733096Z",
     "shell.execute_reply": "2022-03-06T18:31:46.733617Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.867287Z"
    },
    "papermill": {
     "duration": 0.026301,
     "end_time": "2022-03-06T18:31:46.733838",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.707537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(idx_list, window_size, pad_index=0):\n",
    "    nsamples = get_number_of_samples(idx_list, window_size)\n",
    "    winput = np.empty((nsamples, window_size - 1), dtype=np.int32)\n",
    "    target = np.empty(nsamples, dtype=np.int32)\n",
    "    left_window = window_size // 2\n",
    "    right_window = window_size - left_window - 1\n",
    "    sample = 0\n",
    "    for line in idx_list:\n",
    "        if len(line) <= window_size // 2:\n",
    "            continue\n",
    "        ext_line = [pad_index] * left_window + line + [pad_index] * right_window\n",
    "        for i, token_id in enumerate(line):\n",
    "            winput[sample] = ext_line[i:i + left_window] + ext_line[i + left_window + 1:i + window_size]\n",
    "            target[sample] = token_id\n",
    "            sample += 1\n",
    "    assert nsamples == sample\n",
    "    return winput, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cd3ce1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.774122Z",
     "iopub.status.busy": "2022-03-06T18:31:46.773387Z",
     "iopub.status.idle": "2022-03-06T18:31:46.776223Z",
     "shell.execute_reply": "2022-03-06T18:31:46.775655Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.893937Z"
    },
    "papermill": {
     "duration": 0.028337,
     "end_time": "2022-03-06T18:31:46.776362",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.748025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(params):\n",
    "    dataset_prefix = params.dataset\n",
    "    working_prefix = params.working\n",
    "    cutoff = params.cutoff\n",
    "    maxtokens = params.maxtokens\n",
    "    window_size = params.window_size\n",
    "\n",
    "    data = []\n",
    "    for part in ['train', 'valid', 'test']:\n",
    "        data_filename = f'{dataset_prefix}.{part}.tokens'\n",
    "        data_filename_nopunct = f'{working_prefix}.{part}.tokens.nopunct'\n",
    "        remove_punctuation(data_filename, data_filename_nopunct)\n",
    "\n",
    "        if part == 'train':\n",
    "            # Basic token statistics\n",
    "            token_counter = get_token_counter(data_filename_nopunct)\n",
    "            print(f'Number of Tokens: {sum(token_counter.values())}')\n",
    "            print(f'Number of different Tokens: {len(token_counter)}')\n",
    "            pickle.dump(token_counter, open(f'{data_filename_nopunct}.dic', 'wb'))\n",
    "\n",
    "            # Token vocabulary\n",
    "            token_vocab = get_token_vocabulary(token_counter, cutoff=cutoff, maxtokens=maxtokens)\n",
    "            token_vocab.save(f'{working_prefix}.vocab')\n",
    "            print(f'Vocabulary size: {len(token_vocab)}')\n",
    "\n",
    "        # Token indexes\n",
    "        train_idx = get_token_index(data_filename_nopunct, token_vocab)\n",
    "        print(f'Number of lines ({part}): {len(train_idx)}')\n",
    "\n",
    "        # Get input and target arrays\n",
    "        idata, target = get_data(train_idx, window_size)\n",
    "        data.append((idata, target))\n",
    "        print(f'Number of samples ({part}): {len(target)}')\n",
    "\n",
    "        # Save numpy arrays\n",
    "        np.savez(f'{working_prefix}.{part}.npz', idata=idata, target=target)\n",
    "    return token_vocab, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc33f1",
   "metadata": {},
   "source": [
    "## Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b9fa72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.817608Z",
     "iopub.status.busy": "2022-03-06T18:31:46.816197Z",
     "iopub.status.idle": "2022-03-06T18:31:46.819078Z",
     "shell.execute_reply": "2022-03-06T18:31:46.819919Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.917143Z"
    },
    "papermill": {
     "duration": 0.02685,
     "end_time": "2022-03-06T18:31:46.820133",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.793283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create working dir\n",
    "pathlib.Path(WORKING_ROOT).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81315bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:31:46.862091Z",
     "iopub.status.busy": "2022-03-06T18:31:46.861067Z",
     "iopub.status.idle": "2022-03-06T18:40:31.474399Z",
     "shell.execute_reply": "2022-03-06T18:40:31.473854Z",
     "shell.execute_reply.started": "2022-03-06T18:20:35.942004Z"
    },
    "papermill": {
     "duration": 524.633487,
     "end_time": "2022-03-06T18:40:31.474563",
     "exception": false,
     "start_time": "2022-03-06T18:31:46.841076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 82964371\n",
      "Number of different Tokens: 998289\n",
      "OOV ratio: 3.19%.\n",
      "Vocabulary size: 100002\n",
      "Number of lines (train): 1821485\n",
      "Number of samples (train): 82284341\n",
      "Number of lines (valid): 3468\n",
      "Number of samples (valid): 164765\n",
      "Number of lines (test): 3751\n",
      "Number of samples (test): 165837\n"
     ]
    }
   ],
   "source": [
    "vocab, data = prepare_dataset(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ef148",
   "metadata": {
    "papermill": {
     "duration": 0.386487,
     "end_time": "2022-03-06T18:40:35.463575",
     "exception": false,
     "start_time": "2022-03-06T18:40:35.077088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check the vocabulary with some words with specific Catalan characters as 'ï' and 'l·l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ec5a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T18:40:35.507085Z",
     "iopub.status.busy": "2022-03-06T18:40:35.506244Z",
     "iopub.status.idle": "2022-03-06T18:40:35.512350Z",
     "shell.execute_reply": "2022-03-06T18:40:35.513004Z",
     "shell.execute_reply.started": "2022-03-06T18:31:12.095426Z"
    },
    "papermill": {
     "duration": 0.029865,
     "end_time": "2022-03-06T18:40:35.513262",
     "exception": false,
     "start_time": "2022-03-06T18:40:35.483397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token to index:\n",
      "raïm -> 8428\n",
      "intel·ligent -> 7466\n",
      "\n",
      "index to token:\n",
      "8428 -> raïm\n",
      "7466 -> intel·ligent\n"
     ]
    }
   ],
   "source": [
    "print('token to index:')\n",
    "for word in ['raïm', 'intel·ligent']:\n",
    "    index = vocab.get_index(word)\n",
    "    print(f'{word} -> {index}')\n",
    "\n",
    "print('\\nindex to token:')\n",
    "for index in [8428, 7466]:\n",
    "    word = vocab.get_token(index)\n",
    "    print(f'{index} -> {word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc199c3",
   "metadata": {},
   "source": [
    "## Final closures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d5927",
   "metadata": {},
   "source": [
    "The notebook was developped by J.A Fonollosa originally in Kaggle. The model definition in the Crystal Gazers project will bere-created in the .py format to be used in the pipeline creation in the input pre-processing step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 540.412272,
   "end_time": "2022-03-06T18:40:36.358141",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-06T18:31:35.945869",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
