{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-12 19:53:57 Starting - Starting the training job...\n",
      "2022-10-12 19:54:21 Starting - Preparing the instances for trainingProfilerReport-1665604437: InProgress\n",
      ".........\n",
      "2022-10-12 19:55:49 Downloading - Downloading input data...\n",
      "2022-10-12 19:56:09 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,053 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,055 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,063 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,072 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,937 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,948 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,960 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-12 19:57:10,968 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 2048,\n",
      "        \"embedding_dim\": 256,\n",
      "        \"epochs\": 4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-10-12-19-53-57-008\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-3-113121635833/pytorch-training-2022-10-12-19-53-57-008/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"SM_train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"SM_train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":2048,\"embedding_dim\":256,\"epochs\":4}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=SM_train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=SM_train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-3-113121635833/pytorch-training-2022-10-12-19-53-57-008/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":2048,\"embedding_dim\":256,\"epochs\":4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-10-12-19-53-57-008\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-3-113121635833/pytorch-training-2022-10-12-19-53-57-008/source/sourcedir.tar.gz\",\"module_name\":\"SM_train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"SM_train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"2048\",\"--embedding_dim\",\"256\",\"--epochs\",\"4\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=2048\u001b[0m\n",
      "\u001b[34mSM_HP_EMBEDDING_DIM=256\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221002-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 SM_train_model.py --batch-size 2048 --embedding_dim 256 --epochs 4\u001b[0m\n",
      "\n",
      "2022-10-12 19:57:09 Training - Training image download completed. Training in progress.\u001b[34mWARNING: Training without GPU can be very slow!\u001b[0m\n",
      "\u001b[34mNumber of samples (train): 1653615\u001b[0m\n",
      "\u001b[34mNumber of samples (valid): 164765\u001b[0m\n",
      "\u001b[34mUsing precomputed vocabulary and data files\u001b[0m\n",
      "\u001b[34mVocabulary size: 35152\u001b[0m\n",
      "\u001b[34mPredictor(\n",
      "  (emb): Embedding(35152, 256, padding_idx=0)\n",
      "  (lin): Linear(in_features=256, out_features=35152, bias=False)\n",
      "  (att1): TransformerLayer(\n",
      "    (self_attn): SelfAttention(\n",
      "      (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (multihead_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (att2): TransformerLayer(\n",
      "    (self_attn): SelfAttention(\n",
      "      (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (multihead_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34mposition_embedding   1536 [6, 256]\u001b[0m\n",
      "\u001b[34memb.weight           8998912 [35152, 256]\u001b[0m\n",
      "\u001b[34mlin.weight           8998912 [35152, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.k_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.k_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.v_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.v_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.q_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.q_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.out_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.out_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.multihead_attn.in_proj_weight 196608 [768, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.multihead_attn.in_proj_bias 768 [768]\u001b[0m\n",
      "\u001b[34matt1.self_attn.multihead_attn.out_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt1.self_attn.multihead_attn.out_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt1.linear1.weight  131072 [512, 256]\u001b[0m\n",
      "\u001b[34matt1.linear1.bias    512 [512]\u001b[0m\n",
      "\u001b[34matt1.linear2.weight  131072 [256, 512]\u001b[0m\n",
      "\u001b[34matt1.linear2.bias    256 [256]\u001b[0m\n",
      "\u001b[34matt1.norm1.weight    256 [256]\u001b[0m\n",
      "\u001b[34matt1.norm1.bias      256 [256]\u001b[0m\n",
      "\u001b[34matt1.norm2.weight    256 [256]\u001b[0m\n",
      "\u001b[34matt1.norm2.bias      256 [256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.k_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.k_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.v_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.v_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.q_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.q_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.out_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.out_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.multihead_attn.in_proj_weight 196608 [768, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.multihead_attn.in_proj_bias 768 [768]\u001b[0m\n",
      "\u001b[34matt2.self_attn.multihead_attn.out_proj.weight 65536 [256, 256]\u001b[0m\n",
      "\u001b[34matt2.self_attn.multihead_attn.out_proj.bias 256 [256]\u001b[0m\n",
      "\u001b[34matt2.linear1.weight  131072 [512, 256]\u001b[0m\n",
      "\u001b[34matt2.linear1.bias    512 [512]\u001b[0m\n",
      "\u001b[34matt2.linear2.weight  131072 [256, 512]\u001b[0m\n",
      "\u001b[34matt2.linear2.bias    256 [256]\u001b[0m\n",
      "\u001b[34matt2.norm1.weight    256 [256]\u001b[0m\n",
      "\u001b[34matt2.norm1.bias      256 [256]\u001b[0m\n",
      "\u001b[34matt2.norm2.weight    256 [256]\u001b[0m\n",
      "\u001b[34matt2.norm2.bias      256 [256]\u001b[0m\n",
      "\u001b[34mTOTAL                19579904\u001b[0m\n",
      "\u001b[34mTrain: wpb=2048, num_updates=200, accuracy=13.4, loss=6.81\u001b[0m\n",
      "\u001b[34mTrain: wpb=2046, num_updates=808, accuracy=31.4, loss=4.28\u001b[0m\n",
      "\u001b[34m| epoch 001 | train accuracy=31.4%, train loss=4.28\u001b[0m\n",
      "\u001b[34m| epoch 001 | valid accuracy=33.8%, valid loss=4.38 (wikipedia)\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-54a7ea1dcec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             hyperparameters = {'epochs': 4, 'batch-size': 2048, 'embedding_dim': 256})\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m's3://crystal-gazers/preprocessed/ca-2/'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 * (dict[str, str] or dict[str, sagemaker.inputs.TrainingInput] or\n\u001b[1;32m   1063\u001b[0m                     dict[str, sagemaker.inputs.FileSystemInput]) If using multiple channels for\n\u001b[0;32m-> 1064\u001b[0;31m                     \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mspecify\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstrings\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m                     \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingInput\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                     \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileSystemInput\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEstimator\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m             \u001b[0mprofiler_rule_configs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprofiler\u001b[0m \u001b[0mrule\u001b[0m \u001b[0mconfigurations\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                 \u001b[0mupdated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m             \u001b[0mprofiler_config\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConfiguration\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhow\u001b[0m \u001b[0mprofiling\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0memitted\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                 \u001b[0mSageMaker\u001b[0m \u001b[0mDebugger\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3802\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             _flush_log_streams(\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0mstream_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m                 \u001b[0minstance_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pytorch_estimator = PyTorch('SM_train_model.py',\n",
    "                            instance_type='ml.m5.xlarge',\n",
    "                            instance_count=1,\n",
    "                            framework_version='1.12',\n",
    "                            py_version='py38',\n",
    "                            role=role,\n",
    "                            source_dir = '../src/models/',\n",
    "                            hyperparameters = {'epochs': 4, 'batch-size': 2048, 'embedding_dim': 256})\n",
    "                            \n",
    "pytorch_estimator.fit({'train': 's3://crystal-gazers/preprocessed/ca-2/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pytorch_estimator.deploy(instance_type='ml.m5.xlarge',\n",
    "                                     initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict([\"una\", \"vaca\", \"vella\", \"per\", \"la\", \"muntanya\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = 's3://crystal-gazers/models/ca-100/model.tar.gz'\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    model_data=model_data,\n",
    "    framework_version='1.12',\n",
    "    py_version='py38',\n",
    "    role=role,\n",
    "    source_dir = '../src/models/'\n",
    ")\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.pytorch.model.PyTorchModel object at 0x7fa8150b3610>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = {\"input\": [\"la\", \"senyora\", \"vella\", \"per\", \"la\", \"muntanya\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictor.predict(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'i'}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-3:615547856133:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e096f617857432740e200d4afeb73474e977d0e98c70b355e6eaccd2218014ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
